const path = require('path')
const parser = require('./migrationtable')
const { BuildError, hasOptionValue } = require('../../util')
const { LOG_MODULE_NAMES } = require('../../constants')
const cds = require('../../cds'), { compiler: cdsc } = cds
const cdscVersion = `-- generated by cds-compiler version ${cdsc.version()}`
const { getArtifactCdsPersistenceName } = cdsc
let logger = cds.log(LOG_MODULE_NAMES)
const ANNO_PERSISTENCE_JOURNAL = '@cds.persistence.journal'

module.exports = async (model, lastDevVersion, srcPath, options = {}) => {
  if (options.logger) {
    logger = options.logger
  }

  const journalFileNames = _getJournalFileNames(model)
  const { definitions, deletions, migrations, afterImage } = _toHdiMigration(model, lastDevVersion, journalFileNames, options)
  const definitionResult = []

  for (const { name, suffix, sql } of definitions) {
    let definitionEntry = { name, suffix, content: sql }

    if (suffix === '.hdbtable') {
      if (journalFileNames.has(name)) {
        const migration = migrations.find(migration => migration.name === name)
        definitionEntry = await _2migrationtable(srcPath, migration || _emptyMigration(name), sql)
      }
    }
    if (definitionEntry) {
      definitionResult.push(definitionEntry)
    }
  }
  return { definitions: definitionResult, deletions, afterImage: _filterJournalArtifacts(afterImage) }
}

function _toHdiMigration(model, lastDevVersion, journalFileNames, options) {
  const result = cdsc.to.hdi.migration(cds.minify(model), options, lastDevVersion);
  if (logger._debug) {
    logger.debug('cdsc.to.hdi.migration returned')
    for (const { name, suffix, sql } of result.definitions) {
      if (suffix === '.hdbtable' || suffix === '.hdbmigrationtable') {
        if (journalFileNames.has(name)) {
          const migration = result.migrations.find(migration => migration.name === name)
          logger.debug(`
File ${name + '.hdbmigrationtable'} - ${migration ? migration.changeset.length : 0} new changes
${sql}
${migration ? migration.changeset.map(change => change.sql).join('\n') : 'Empty changeset'}
`)
        }
      }
    }
  }
  return result
}

/**
 * Returns an object providing access to the .hdbmigrationtable file content and its corresponding filename.
 *
 * @param {String} srcPath Fully qualified path of the directory containing .hdbmigrationtable files
 * @param {String} migration the migration descriptor
 * @param {String} tableSql SQL TABLE definition
 * @returns {Object} Providing access to 'content' and 'fileName'.
 */
async function _2migrationtable(srcPath, migration, tableSql) {
  let migrationTableModel = null
  const file = path.join(srcPath, migration.name + migration.suffix)
  try {
    migrationTableModel = await parser.read(file)
  } catch (e) {
    // abort build in order to ensure consistent afterImage model state / hdbmigrationtable file state
    throw new BuildError(`${path.relative(process.cwd(), file)}: ${e.message}`)
  }

  if (migrationTableModel) {
    // adding new changeset if change exist, ignore otherwise
    const migrationEntry = _getNewMigrationEntry(migration.changeset, migrationTableModel.versionNumber)
    if (migrationEntry) {
      const versionNumber = migrationTableModel.versionNumber + 1
      const migrationCount = migrationTableModel.migrations.entries.length
      const migrations = `${migrationEntry.content}${migrationCount > 0 ? '\n' : ''}${migrationTableModel.migrations.toString()}${migrationCount > 0 ? '\n' : ''}`
      return {
        name: migration.name,
        suffix: migration.suffix,
        content: `== version=${versionNumber}\n${tableSql}\n\n${migrations}`,
        changed: true,
        dropColumns: migrationEntry.dropColumns
      }
    } else {
      // existing migration file version
      return { name: migration.name, suffix: migration.suffix, content: migrationTableModel.toString(), changed: false }
    }
  }
  // initial migration file version
  return { name: migration.name, suffix: migration.suffix, content: `== version=1\n${tableSql}\n`, changed: true }
}

function _getNewMigrationEntry(changeset, currentVersion) {
  if (changeset && changeset.length > 0) {
    const dropColumns = changeset.some(e => e.drop)
    const manualChange = changeset.some(e => !e.sql)
    const enableDrop = cds.env.hana?.journal?.['enable-drop']
    const content = changeset.reduce((acc, e) => {
      if (!acc) {
        acc = `== migration=${currentVersion + 1}\n`
        acc += `${cdscVersion}\n`

        if (dropColumns && enableDrop !== true) {
          acc += `>>>>> Manual resolution required - DROP statements causing data loss are disabled by default.
>>>>> You may either:
>>>>>   uncomment statements to allow incompatible changes, or
>>>>>   refactor statements, e.g. replace DROP/ADD by single RENAME statement
>>>>> After manual resolution delete all lines starting with >>>>>\n`
        } else if (manualChange) {
          acc += `>>>>> Manual resolution required - insert ALTER statement(s) as described below.
>>>>> After manual resolution delete all lines starting with >>>>>\n`
        }
      }
      if (e.sql) {
        if (e.drop && enableDrop !== true) {
          acc += `${e.sql.replace(/^/gm, '-- ')}\n`;
        } else {
          acc += `${e.sql}\n`
        }
      } else {
        acc +=
          `>>>>> Insert ALTER statement for: ${e.description}\n`
      }
      return acc
    }, null)
    return { dropColumns, content }
  }
  return null
}

function _emptyMigration(name) {
  return { name, suffix: ".hdbmigrationtable", changeset: [] }
}

function _getJournalFileNames(model) {
  const journalNames = new Set(cds.reflect(model).all(item => {
    if (item.kind === 'entity' && item[ANNO_PERSISTENCE_JOURNAL] === true) {
      if (item['@cds.persistence.skip'] === true || item['@cds.persistence.exists'] === true) {
        logger.warn(`[hdbmigrationtable] annotation @cds.persistence.journal skipped for entity '${item.name}' as persistence exists`)
      }
      return true
    }
    return false
  }).map(entity => getArtifactCdsPersistenceName(entity.name, 'quoted', model, 'hana')))

  logger._debug && logger.debug(`\n[hdbmigrationtable] found ${journalNames.size} model entities annotated with '@cds.persistence.journal`)
  logger._debug && logger.debug(`[hdbmigrationtable] ${[...journalNames].join(', ')}\n`)

  return journalNames
}

// delete all entities that are not relevant
function _filterJournalArtifacts(csn) {
  if (!csn) {
    return
  }
  const dict = csn.definitions
  for (const name in dict) {
    if (!_isPersistedAsJournalTable(dict[name])) {
      delete dict[name]
    }
  }
  // mark CSN as modified by cds build
  csn.meta.build = `CDS Build v${cds.version}`
  return csn;
}

// see cds-compiler/lib/model/csnUtils.js#isPersistedAsTable
function _isPersistedAsJournalTable(artifact) {
  return artifact.kind === 'entity' && hasOptionValue(artifact['@cds.persistence.journal'], true) &&
    !artifact.abstract &&
    !hasOptionValue(artifact['@cds.persistence.skip'], true) &&
    !hasOptionValue(artifact['@cds.persistence.exists'], true) &&
    (!artifact.query && !artifact.projection || hasOptionValue(artifact['@cds.persistence.table'], true))
}
