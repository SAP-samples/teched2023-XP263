const fs = require('fs')
const path = require('path')
const cds = require('../../cds')
const BuildTaskHandlerInternal = require('../buildTaskHandlerInternal')
const { OUTPUT_MODE_RESULT_ONLY, BUILD_OPTION_OUTPUT_MODE, SKIP_HDBTABLEDATA_GENERATION, SKIP_PACKAGE_JSON_GENERATION,
    CONTENT_PACKAGE_JSON, CONTENT_HDBTABLEDATA, CSV_FILE_DETECTION, CONTENT_ENV, CONTENT_DEFAULT_ENV_JSON, CONTENT_NODE_MODULES } = require('../../constants')
const { BuildError, relativePaths } = require('../../util')
const CSV = require('../../csv-reader')
const to_hdbmigration = require('./2migration')
const to_hdbtabledata = require('./2tabledata')
const { ERROR, WARNING } = require('../../buildTaskHandler')

const DEFAULT_COMPILE_DEST_FOLDER = path.normalize("src/gen")

const FILE_EXT_CSV = ".csv"
const FILE_EXT_HDBTABLEDATA = ".hdbtabledata"
const FILE_EXT_HDBTABLE = ".hdbtable"
const FILE_EXT_HDBMIGRATIONTABLE = ".hdbmigrationtable"

const FILE_NAME_HDICONFIG = ".hdiconfig"
const FILE_NAME_HDINAMESPACE = ".hdinamespace"
const FILE_NAME_PACKAGE_JSON = "package.json"
const PATH_LAST_DEV_CSN = "last-dev/csn.json"
const FILE_NAME_UNDEPLOY_JSON = "undeploy.json"

const DEPLOY_FORMAT = "deploy-format"

// add well-known types supported by HANA Cloud Edition - see also https://github.wdf.sap.corp/cap/issues/issues/8056
const REQUIRED_PLUGIN_TYPES = [FILE_EXT_CSV, FILE_EXT_HDBTABLEDATA, FILE_EXT_HDBTABLE, ".hdbview", ".hdbindex", ".hdbconstraint"]
class HanaModuleBuilder extends BuildTaskHandlerInternal {
    init() {
        this._result = {
            dest: this.task.dest,
            hana: []
        }

        // set unified option values in order to easy access later on
        // default value: true
        this.task.options[CONTENT_PACKAGE_JSON] = !this.hasBuildOption(CONTENT_PACKAGE_JSON, false) && !this.hasBuildOption(SKIP_PACKAGE_JSON_GENERATION, true) ? true : false
        this.task.options[CONTENT_HDBTABLEDATA] = !this.hasBuildOption(CONTENT_HDBTABLEDATA, false) && !this.hasBuildOption(SKIP_HDBTABLEDATA_GENERATION, true) ? true : false
        this.task.options[CSV_FILE_DETECTION] = !this.hasBuildOption(CSV_FILE_DETECTION, false) ? true : false

        // default value: false
        this.task.options[CONTENT_NODE_MODULES] = this.hasBuildOption(CONTENT_NODE_MODULES, true) ? true : false
        this.task.options[CONTENT_ENV] = this.hasBuildOption(CONTENT_ENV, true) ? true : false
        this.task.options[CONTENT_DEFAULT_ENV_JSON] = this.hasBuildOption(CONTENT_DEFAULT_ENV_JSON, true) ? true : false

        this.task.options.compileDest = path.resolve(this.task.dest, this.task.options.compileDest || DEFAULT_COMPILE_DEST_FOLDER)
    }

    async build() {
        const { src, dest } = this.task
        const model = await this.model()
        if (!model) {
            return this._result
        }
        const plugins = await this._compileToHana(model)

        if (!this.hasBuildOption(BUILD_OPTION_OUTPUT_MODE, OUTPUT_MODE_RESULT_ONLY)) {
            if (this.hasBuildOption(CSV_FILE_DETECTION, false)) {
                await this._copyResources(src, dest)
            } else {
                await this._copyResourcesExt(src, dest, model)
            }

            await this._writeHdiConfig(plugins)
            await this._writeHdiNamespace()

            // TODO disabled as this contradicts the MTX domain concept which allows partial app deployments
            //await this._writeUndeployJson()

            if (this.hasBuildOption(CONTENT_HDBTABLEDATA, true)) {
                await this._compileToHdbtabledata(model, dest)
            }
            if (this.hasBuildOption(CONTENT_PACKAGE_JSON, true)) {
                await this._writePackageJson()
            }
        }
        return this._result
    }

    /**
     * Deletes any content that has been created in folder '#this.task.dest/src/gen' by inplace mode.
     * <br>
     * Note: Content created in staging build will be deleted by the #BuildTaskEngine itself.
     */
    async clean() {
        if (this.isStagingBuild()) {
            return super.clean()
        }
        return fs.promises.rm(this.task.options.compileDest, { force: true, recursive: true })
    }

    /**
     * Copies all files located at <src> (except HANA artifacts not contained in <db>/src/**) to the folder <dest>.
     * '*.csv' files are read based on the corresponding CDS model file location and copied as flat list into folder '<dest>/src/gen>'.
     *
     * @param {string} src
     * @param {string} dest
     * @param {Object} model
     */
    async _copyResourcesExt(src, dest, model) {
        const resources = Object.keys(await cds.deploy.resources(model)).reverse() // reverse to get reuse resources first and app resources last
        const csvPath = path.join(src, "data")
        // determine subfolder name used by the application for backward compatibility
        const csvFolder = resources.some(res => res && res.startsWith(csvPath)) ? "data" : "csv"

        // 1. copy csv files into 'src/gen/data' or 'src/gen/csv' subfolder
        const dbSrc = path.join(src, 'src')

        // await each copy as order is important - reuse resources first and app resources last
        for (const res of resources) {
            // do not duplicate resources that are already contained in db/src/**
            if (res && /\.csv$/.test(res) && !res.startsWith(dbSrc)) {
                await this.copy(res).to(path.join(this.task.options.compileDest, csvFolder, path.basename(res)))
            }
        }

        // 2. staging build: copy files except *.cds, .env, default-env.json, ./node_modules/**
        if (this.isStagingBuild()) {
            let blockList = "\\.cds$|\\.csv$|\\.hdbtabledata$"
            blockList += this.hasBuildOption(CONTENT_ENV, false) ? "|\\.env($|\\..*$)" : ""
            blockList += this.hasBuildOption(CONTENT_DEFAULT_ENV_JSON, false) ? "|default-env\\.json$" : ""
            blockList = new RegExp(blockList)

            await this.copyNativeContent(src, dest, (entry) => {
                if (entry.startsWith(dbSrc)) {
                    // entire native content
                    return true
                }
                if (fs.statSync(entry).isDirectory()) {
                    return !/(\/|\\)node_modules(\/|\\)?$/.test(entry) || this.hasBuildOption(CONTENT_NODE_MODULES, true)
                }
                return !blockList.test(entry)
            })
        }
    }

    /**
     * Copies the entire content of the db module located in the given <src> folder to the folder <dest>.
     * '*.csv' and '*.hdbtabledata' files located in a subfolder 'data' or 'csv' will be copied to '<dest>/src/gen/data>'||'<dest>/src/gen/csv>'
     *
     * @param {string} src
     * @param {string} dest
     */
    async _copyResources(src, dest) {
        const dbCsvDir = path.join(src, "csv")
        const dbDataDir = path.join(src, "data")
        const csvDirs = [dbCsvDir, dbDataDir]
        const regexData = RegExp('\\.csv$|\\.hdbtabledata$')

        if (this.isStagingBuild()) {
            const regex = RegExp('\\.cds$|\\.csv$|\\.hdbtabledata$')

            await this.copyNativeContent(src, dest, (entry) => {
                if (fs.statSync(entry).isDirectory()) {
                    return !/(\/|\\)node_modules(\/|\\)?$/.test(entry)
                }
                return (!regex.test(entry) && entry !== cds.env.build.outputfile) ||
                    (regexData.test(entry) && !entry.startsWith(dbCsvDir) && !entry.startsWith(dbDataDir))
            })
        }

        // handle *.csv and *.hdbtabledata located in '<dbSrc>/data' and '<dbSrc>/csv' folder
        const allFiles = csvDirs.reduce((acc, csvDir) => {
            return acc.concat(BuildTaskHandlerInternal._find(csvDir, (entry) => {
                if (fs.statSync(entry).isDirectory()) {
                    return false
                }
                return regexData.test(entry)
            }))
        }, [])

        return Promise.all(allFiles.map((file) => {
            return this.copy(file).to(path.join(this.task.options.compileDest, path.relative(src, file)))
        }))
    }

    /**
     * Generates *.hdbtabledata files in folder '#this.task.dest/src/gen' from *.csv files located in '#this.task.dest/src/**' folder.
     * The generated *.hdbtabledata files will link to their *.csv counterparts using relative links. The *.csv files have either
     * already been defined in the 'src' folder or they have been copied to '#this.task.dest/src/gen/**' folder if they have been
     * created outside 'src' folder. If custom *.hdbtabledata files are found nothing is generated for this particular folder.
     * <br>
     * Note: *.csv and *.hdbtabledata need to be copied to '#this.task.dest/src/gen**' if required before this method is called.
     * In inplace mode dest folder is refering to src folder.
     *
     * @param {object} model compiled csn
     */
    async _compileToHdbtabledata(model, dest) { //NOSONAR
        const tabledataDirs = new Set()
        const destSrcDir = path.join(dest, "src")

        const allCsvFiles = BuildTaskHandlerInternal._find(destSrcDir, (entry) => {
            if (fs.statSync(entry).isDirectory()) {
                return true
            }
            if (/\.hdbtabledata$/.test(entry)) {
                tabledataDirs.add(path.dirname(entry))
            }
            return /\.csv$/.test(entry)
        })
        if (allCsvFiles.length > 0) {
            const csvDirs = allCsvFiles.map(path.dirname).reduce((dirs, dir) => {
                if (!tabledataDirs.has(dir) && !dirs.includes(dir)) { // exclude any dir where a tabledata is present
                    dirs.push(dir)
                }
                return dirs
            }, [])

            // ODM csv data comes with license comments, so strip these
            if (!this.hasBuildOption("stripCsvComments", false)) {
                await this._stripCsvComments(allCsvFiles)
            }

            const promises = []
            const relDest = path.relative(this.task.dest, this.task.options.compileDest)
            const options = { ...this.options(), logger: this.logger, dirs: csvDirs, baseDir: this.task.options.compileDest }
            const tableDatas = await to_hdbtabledata(model, options)

            for (let [tableData, { file, csvFolder }] of tableDatas) {
                // create .hdbtabledata side-by-side if .csv is contained in 'src/gen/**' subfolder
                // otherwise create in 'src/gen'
                let tableDataPath = csvFolder.startsWith(this.task.options.compileDest) ? csvFolder : this.task.options.compileDest
                tableDataPath = path.join(tableDataPath, file)
                this._result.hana.push(path.join(relDest, file))
                promises.push(this.write(tableData).to(tableDataPath))
            }
            await Promise.all(promises)
        }
    }

    async _stripCsvComments(csvFiles) {
        // Note: modification of csv files is only allowed for files located in the compile destination folder,
        // meaning having their origin location at db/data/* or db/csv/*
        for (const file of csvFiles) {
            if (this.isStagingBuild() || file.startsWith(this.task.options.compileDest)) {
                await CSV.stripComments(file)
            }
        }
    }

    /**
     * Creates the hana artifacts from the given csn model and writes the files to the folder '<dest>/src/gen'.
     *
     * @param {object} model The compiled csn model
     */
    async _compileToHana(model) {
        // see CAP issue #6222
        const undeployTypes = await this._readTypesFromUndeployJson()
        const pluginTypes = new Set([...REQUIRED_PLUGIN_TYPES, ...undeployTypes])

        // compile to old format (.hdbcds) or new format (.hdbtable / .hdbview)
        const format = this.getBuildOption(DEPLOY_FORMAT) || cds.env.requires.db?.[DEPLOY_FORMAT] || cds.env.hana?.[DEPLOY_FORMAT]
        if (!cds.compile.to[format]) {
            return Promise.reject(new Error(`Invalid deploy-format defined: ${format}`))
        }

        if (this.hasCdsEnvOption('features.journal', false) || format === 'hdbcds') {
            await this._compileToHdb(model, pluginTypes, format)
        } else {
            await this._compileToHdbmigration(model, pluginTypes, format)
        }
        return pluginTypes
    }

    async _compileToHdb(model, pluginTypes, format) {
        const relDest = path.relative(this.task.dest, this.task.options.compileDest)
        // enforces sqlNames option for compiler in tests
        const options = { ...this.options(), sql_mapping: cds.env.sql.names }
        const result = cds.compile.to[format](model, options)
        const promises = []

        for (const [content, key] of result) {
            pluginTypes.add(key.suffix || path.extname(key.file))
            const file = key.file ? key.file : key.name + key.suffix
            this._result.hana.push(path.join(relDest, file))
            if (!this.hasBuildOption(BUILD_OPTION_OUTPUT_MODE, OUTPUT_MODE_RESULT_ONLY)) {
                promises.push(this.write(content).to(path.join(this.task.options.compileDest, file)))
            }
        }
        await Promise.all(promises)
    }

    async _compileToHdbmigration(model, pluginTypes, format) {
        const relDestDir = path.relative(this.task.dest, this.task.options.compileDest)
        const relDbDestDir = path.relative(this.buildOptions.root, this.task.options.compileDest)
        const dbSrcDir = path.join(this.task.src, "src")
        const relDbSrcDir = path.relative(this.buildOptions.root, dbSrcDir)
        const lastDevCsnFolder = PATH_LAST_DEV_CSN
        const lastDevCsnDir = path.join(this.task.src, lastDevCsnFolder)
        let lastDev = null
        const promises = []
        const migrationTableFiles = []

        if (fs.existsSync(lastDevCsnDir)) {
            lastDev = JSON.parse((await fs.promises.readFile(lastDevCsnDir, 'utf-8')).toString())
        }
        // enforces sqlNames option for compiler in tests, pass options from cds env, ensures that the correct format is taken
        const options = { ...this.options(), logger: this.logger, sql_mapping: cds.env.sql.names, "deploy-format": format }

        const compilationResult = await to_hdbmigration(model, lastDev, dbSrcDir, options)
        const definitions = compilationResult.definitions
        const afterImage = compilationResult.afterImage

        for (const { name, suffix, content, changed } of definitions) {
            pluginTypes.add(suffix)
            const file = name + suffix
            if (suffix === FILE_EXT_HDBMIGRATIONTABLE) {
                migrationTableFiles.push(path.join(relDbSrcDir, file))
                if (changed) {
                    this._result.hana.push(path.join("src", file))
                    if (!this.hasBuildOption(BUILD_OPTION_OUTPUT_MODE, OUTPUT_MODE_RESULT_ONLY)) {
                        promises.push(this.write(content).to(path.join(dbSrcDir, file)))
                    }
                } else {
                    this.logger._debug && this.logger.debug(`no change, keep existing ${file}`)
                }
            } else {
                this._result.hana.push(path.join(relDestDir, file))
                if (!this.hasBuildOption(BUILD_OPTION_OUTPUT_MODE, OUTPUT_MODE_RESULT_ONLY)) {
                    promises.push(this.write(content).to(path.join(this.task.options.compileDest, file)))
                }
                if (suffix === FILE_EXT_HDBTABLE) {
                    // issue an error in case a .hdbmigrationtable file already exists
                    if (fs.existsSync(path.join(dbSrcDir, name + FILE_EXT_HDBMIGRATIONTABLE))) {
                        throw new BuildError(`Multiple files exist defining the same HANA artifact - [${path.join(relDbSrcDir, name + FILE_EXT_HDBMIGRATIONTABLE)}, ${path.join(relDbDestDir, file)}].\nEither annotate the model entity using @cds.persistence.journal or undeploy the file [${path.join('src', name + FILE_EXT_HDBMIGRATIONTABLE)}] using an undeploy.json file.`)
                    }
                }
            }
        }
        await Promise.all(promises)
        await this._validateMigrationTableFiles()

        // update last development version
        if (afterImage) {
            if (migrationTableFiles.length > 0) {
                if (!HanaModuleBuilder._toEqualIgnoreMeta(lastDev, afterImage)) {
                    await this.write(afterImage).to(lastDevCsnDir)
                }

                // add src/.hdiconfig if not existing
                if (!fs.existsSync(path.join(dbSrcDir, '.hdiconfig'))) {
                    const template = await HanaModuleBuilder._readTemplateAsJson('.hdiconfig-hanacloud')
                    await this.write(template).to(path.join(dbSrcDir, '.hdiconfig'))
                }
            }
        } else {
            throw new BuildError(`Inconsistent CDS compilation results - file ${lastDevCsnFolder} missing`)
        }
    }

    async _writePackageJson() {
        const packageJson = path.join(this.task.src, "package.json")
        const exists = fs.existsSync(packageJson)

        if (exists) {
            this.logger._debug && this.logger.debug(`skip create [${relativePaths(this.buildOptions.root, packageJson)}], already existing`)
        }
        if (this.isStagingBuild() && !exists) {
            const content = await HanaModuleBuilder._readTemplateAsJson(FILE_NAME_PACKAGE_JSON)
            await this.write(content).to(path.join(this.task.dest, FILE_NAME_PACKAGE_JSON))
        }
    }

    /**
     * Create .hdiconfig file in <dest>src/gen folder of db module.
     */
    async _writeHdiConfig(plugins) {
        const hdiConfig = path.join(this.task.options.compileDest, FILE_NAME_HDICONFIG)
        const template = await HanaModuleBuilder._readTemplateAsJson('.hdiconfig-haas')
        let content = {
            'file_suffixes': {}
        }
        for (const key in template['file_suffixes']) {
            if (plugins.has('.' + key)) {
                content['file_suffixes'][key] = template['file_suffixes'][key]
            }
        }
        if (Object.keys(content['file_suffixes']).length !== plugins.size) {
            this.pushMessage(`'HANA database plugin not found for file suffix [${Array.from(plugins).join(',')}]`)
        }
        // TODO - Be on the save side for now - go for the content use case later on if this works as expected.
        if (cds.env.hana['deploy-format'] === 'hdbtable') {
            await this.write(content).to(hdiConfig)
        } else {
            await this.write(template).to(hdiConfig)
        }
    }

    /**
     * Create .hdinamespace file in <dest>src/gen folder of db module.
     */
    async _writeHdiNamespace() {
        // see issue #64 - add .hdinamespace file to prevent HDI from adding gen/ folder to the namespace.
        const hdiNamespace = path.join(this.task.options.compileDest, FILE_NAME_HDINAMESPACE)
        const content = await HanaModuleBuilder._readTemplateAsJson(FILE_NAME_HDINAMESPACE)
        return await this.write(content).to(hdiNamespace)
    }

    /**
     * Create undeploy.json file in <dest> folder of db module.
     */
    async _writeUndeployJson() {
        if (this.isStagingBuild()) {
            // see issue #64 - add .hdinamespace file to prevent HDI from adding gen/ folder to the namespace.
            const undeployJsonDest = path.join(this.task.dest, FILE_NAME_UNDEPLOY_JSON)
            const undeployJsonSrc = path.join(this.task.src, FILE_NAME_UNDEPLOY_JSON)
            const templateEntries = await HanaModuleBuilder._readTemplateAsJson(FILE_NAME_UNDEPLOY_JSON)
            let newEntries = []
            if (fs.existsSync(undeployJsonSrc)) {
                newEntries = await JSON.parse((await fs.promises.readFile(undeployJsonSrc, 'utf-8')).toString())
                newEntries = Array.isArray(newEntries) ? newEntries : []
                templateEntries.forEach(entry => {
                    if (!newEntries.includes(entry)) {
                        newEntries.push(entry)
                    }
                })
            } else {
                newEntries = templateEntries
            }
            // formatted output
            let content = '[\n'
            for (let i = 0; i < newEntries.length; i++) {
                content += `  "${newEntries[i]}"${i + 1 < newEntries.length ? ',' : ''}\n`
            }
            content += ']'
            await this.write(content).to(undeployJsonDest)
        }
    }


    async _readTypesFromUndeployJson() {
        const result = new Set()
        const file = path.join(this.task.src, "undeploy.json")

        if (fs.existsSync(file)) {
            const undeployList = JSON.parse((await fs.promises.readFile(file)).toString(), 'utf-8')
            if (Array.isArray(undeployList)) {
                const hdiconfig = await HanaModuleBuilder._readTemplateAsJson('.hdiconfig-haas')
                const keys = new Set(Object.keys(hdiconfig['file_suffixes']).map(key => '.' + key))
                undeployList.forEach(entry => {
                    const extName = path.extname(entry)
                    if (extName && !result.has(extName)) {
                        if (keys.has(extName)) {
                            result.add(extName)
                        } else {
                            this.pushMessage(`Ignoring invalid entry '${entry}' in undeploy.json file`, WARNING)
                        }
                    }
                })
            }
        }
        return result
    }

    async _validateMigrationTableFiles() {
        const dbSrcDir = path.join(this.task.src, "src")
        const migrationTableFiles = BuildTaskHandlerInternal._find(dbSrcDir, (res) => {
            return fs.statSync(res).isFile() && path.extname(res) === FILE_EXT_HDBMIGRATIONTABLE
        })
        if (migrationTableFiles.length > 0) {
            const parser = require('./migrationtable')

            await Promise.all(migrationTableFiles.map(async file => {
                try {
                    const tableModel = await parser.read(file)
                    if (/^>>>>>/m.test(tableModel.migrations.toString())) {
                        // as this is not a build error, we do not abort cds build, instead only log as error
                        this.pushMessage(`Current model changes require manual resolution. See migration file ${path.relative(this.buildOptions.root, file)} for further details.`, ERROR)
                    }
                } catch (e) {
                    throw new Error(`${path.relative(this.buildOptions.root, file)}: ${e.toString()}`, ERROR)
                }
            }))
        }
    }

    static async _readTemplateAsJson(template) {
        const content = await fs.promises.readFile(path.join(__dirname, 'template', template), 'utf-8')
        return JSON.parse(content.toString())
    }

    static _toEqualIgnoreMeta(csn1, csn2) {
        function toString(csn) {
            return JSON.stringify(csn, (k, v) => {
                if (v?.creator) {
                    // make sure it's the compiler meta tag
                    if (k === 'meta' && v.creator?.startsWith('CDS Compiler'))
                        return
                }
                return v
            })
        }

        if (csn1 === csn2) {
            return true
        }
        if (!csn1 || !csn2) {
            return false
        }
        return toString(csn1) === toString(csn2)
    }
}
module.exports = HanaModuleBuilder
